
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['object', 'robot0_gripper_qpos', 'robot0_eef_quat', 'robot0_eef_pos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
[robosuite WARNING] No private macro file found! (macros.py:53)
[robosuite WARNING] It is recommended to use a private macro file (macros.py:54)
[robosuite WARNING] To setup, run: python /opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)
Created environment with name PickPlaceCan
Action size is 7
PickPlaceCan
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}

OpenAI client initialized

============= Model Summary =============
KAT (
  ModuleDict()
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/200 [00:00<?, ?it/s]  9%|9         | 18/200 [00:00<00:01, 179.75it/s] 18%|#8        | 36/200 [00:00<00:00, 166.40it/s] 26%|##6       | 53/200 [00:00<00:00, 161.80it/s] 35%|###5      | 70/200 [00:00<00:00, 157.35it/s] 44%|####3     | 87/200 [00:00<00:00, 160.34it/s] 54%|#####4    | 108/200 [00:00<00:00, 175.55it/s] 63%|######3   | 126/200 [00:00<00:00, 171.17it/s] 72%|#######2  | 145/200 [00:00<00:00, 174.87it/s] 82%|########1 | 163/200 [00:00<00:00, 176.31it/s] 90%|######### | 181/200 [00:01<00:00, 151.16it/s] 98%|#########8| 197/200 [00:01<00:00, 141.80it/s]100%|##########| 200/200 [00:01<00:00, 157.30it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/23207 [00:00<?, ?it/s]  2%|2         | 522/23207 [00:00<00:04, 5212.34it/s]  5%|4         | 1141/23207 [00:00<00:03, 5784.61it/s]  8%|8         | 1894/23207 [00:00<00:03, 6579.65it/s] 12%|#2        | 2793/23207 [00:00<00:02, 7529.62it/s] 16%|#6        | 3769/23207 [00:00<00:02, 8331.75it/s] 21%|##        | 4793/23207 [00:00<00:02, 8975.53it/s] 25%|##4       | 5755/23207 [00:00<00:01, 9183.21it/s] 29%|##8       | 6720/23207 [00:00<00:01, 9331.15it/s] 33%|###2      | 7654/23207 [00:00<00:01, 8635.22it/s] 37%|###6      | 8528/23207 [00:01<00:01, 8580.85it/s] 41%|####1     | 9552/23207 [00:01<00:01, 9064.16it/s] 45%|####5     | 10466/23207 [00:01<00:01, 8429.13it/s] 49%|####8     | 11322/23207 [00:01<00:01, 7629.34it/s] 52%|#####2    | 12105/23207 [00:01<00:01, 6756.40it/s] 56%|#####5    | 12909/23207 [00:01<00:01, 7077.24it/s] 59%|#####8    | 13642/23207 [00:01<00:01, 6773.20it/s] 62%|######1   | 14337/23207 [00:01<00:01, 6713.04it/s] 65%|######5   | 15089/23207 [00:01<00:01, 6927.66it/s] 68%|######8   | 15887/23207 [00:02<00:01, 7217.88it/s] 72%|#######2  | 16725/23207 [00:02<00:00, 7543.11it/s] 76%|#######6  | 17704/23207 [00:02<00:00, 8189.82it/s] 81%|########  | 18714/23207 [00:02<00:00, 8744.87it/s] 85%|########4 | 19715/23207 [00:02<00:00, 6362.47it/s] 89%|########8 | 20604/23207 [00:02<00:00, 6933.71it/s] 93%|#########3| 21658/23207 [00:02<00:00, 7815.58it/s] 98%|#########7| 22637/23207 [00:02<00:00, 8326.39it/s]100%|##########| 23207/23207 [00:02<00:00, 7778.90it/s]

============= Training Dataset =============
SequenceDataset (
	path=tmp/can.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=1
	filter_key=none
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=200
	num_sequences=23207
)

**************************************************
Warnings generated by robomimic have been duplicated here (from above) for convenience. Please check them carefully.
**************************************************

  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:00<00:00,  1.61it/s]100%|##########| 1/1 [00:00<00:00,  1.61it/s]
Train Epoch 1
{
    "Time_Data_Loading": 0.00044395128885904946,
    "Time_Epoch": 0.010753417015075683,
    "Time_Log_Info": 1.8278757731119793e-07,
    "Time_Process_Batch": 5.9998035430908204e-05,
    "Time_Train_Batch": 0.009868947664896648
}
video writes to /Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/../kat_trained_models/test/20240725115104/videos/PickPlaceCan_epoch_1.mp4
rollout: env=PickPlaceCan, horizon=3000, use_goals=False, num_episodes=10
  0%|          | 0/10 [00:00<?, ?it/s]An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 169429 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 1.82 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 169429 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 2.79 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 169429 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 4.81 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 169429 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 8.17 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 169429 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 16.59 seconds...
  0%|          | 0/10 [01:17<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 427, in <module>
    main(args)
  File "train.py", line 378, in main
    train(config, device=device)
  File "train.py", line 263, in train
    all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/utils/train_utils.py", line 363, in rollout_with_stats
    rollout_info = run_rollout(
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/utils/train_utils.py", line 226, in run_rollout
    ac = policy(ob=ob_dict, goal=goal_dict)
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/algo/algo.py", line 525, in __call__
    ac = self.policy.get_action(obs_dict=ob, goal_dict=goal)
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/algo/kat.py", line 239, in get_action
    self.kat_action_list = self.open_ai_client.process_test(self.prompt_path, instruction, scene_objects, context_description)
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/llminterface/llm_utils.py", line 232, in process_test
    time.sleep(60)
KeyboardInterrupt
