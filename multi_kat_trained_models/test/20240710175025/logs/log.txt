
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['object', 'robot0_gripper_qpos', 'robot0_eef_quat', 'robot0_eef_pos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
[robosuite WARNING] No private macro file found! (macros.py:53)
[robosuite WARNING] It is recommended to use a private macro file (macros.py:54)
[robosuite WARNING] To setup, run: python /opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}

OpenAI client initialized

============= Model Summary =============
Multi_KAT (
  ModuleDict()
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/200 [00:00<?, ?it/s] 13%|#3        | 26/200 [00:00<00:00, 258.81it/s] 26%|##6       | 53/200 [00:00<00:00, 264.75it/s] 42%|####1     | 83/200 [00:00<00:00, 278.77it/s] 56%|#####5    | 111/200 [00:00<00:00, 271.68it/s] 70%|######9   | 139/200 [00:00<00:00, 259.54it/s] 83%|########2 | 166/200 [00:00<00:00, 259.31it/s] 96%|#########6| 193/200 [00:00<00:00, 262.39it/s]100%|##########| 200/200 [00:00<00:00, 265.04it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/9666 [00:00<?, ?it/s]  9%|8         | 831/9666 [00:00<00:01, 8308.58it/s] 19%|#8        | 1835/9666 [00:00<00:00, 9323.26it/s] 29%|##8       | 2768/9666 [00:00<00:00, 9006.10it/s] 38%|###8      | 3713/9666 [00:00<00:00, 9176.78it/s] 50%|#####     | 4842/9666 [00:00<00:00, 9927.70it/s] 60%|######    | 5837/9666 [00:00<00:00, 9815.28it/s] 71%|#######1  | 6874/9666 [00:00<00:00, 9992.78it/s] 82%|########1 | 7917/9666 [00:00<00:00, 10124.65it/s] 92%|#########2| 8931/9666 [00:00<00:00, 9474.16it/s] 100%|##########| 9666/9666 [00:01<00:00, 9277.24it/s]

============= Training Dataset =============
SequenceDataset (
	path=tmp/lift.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=1
	filter_key=none
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=200
	num_sequences=9666
)

**************************************************
Warnings generated by robomimic have been duplicated here (from above) for convenience. Please check them carefully.
**************************************************

  0%|          | 0/1 [00:00<?, ?it/s]API call successful.
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 132379 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 1.94 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 132379 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 2.82 seconds...
An error occurred: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 132379 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Retrying in 4.75 seconds...
  0%|          | 0/1 [02:46<?, ?it/s]
Traceback (most recent call last):
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/llminterface/llm_utils.py", line 71, in lm
    response = self.client.chat.completions.create(
  File "/opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/openai/resources/chat/completions.py", line 643, in create
    return self._post(
  File "/opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/openai/_base_client.py", line 1250, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/openai/_base_client.py", line 931, in request
    return self._request(
  File "/opt/miniconda3/envs/robomimic_venv/lib/python3.8/site-packages/openai/_base_client.py", line 1030, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 132379 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 427, in <module>
    main(args)
  File "train.py", line 378, in main
    train(config, device=device)
  File "train.py", line 196, in train
    step_log = TrainUtils.run_epoch(
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/utils/train_utils.py", line 559, in run_epoch
    info = model.train_on_batch(input_batch, epoch, validate=validate)
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/algo/multi_kat.py", line 308, in train_on_batch
    self._add_requestable_demonstration_data()
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/robomimic/algo/multi_kat.py", line 251, in _add_requestable_demonstration_data
    help_needed = self.open_ai_client.process_ensemble_training("_demo_data_temp.txt", instruction, scene_objects, context_description, self.ensemble_size, temperature=0.2)
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/llminterface/llm_utils.py", line 295, in process_ensemble_training
    response, text = self.lm(self.system_prompt, max_tokens=1, logprobs=True, top_logprobs=5, response_format={"type": "text"})
  File "/Users/sarthakdas/Library/Mobile Documents/com~apple~CloudDocs/ComputerScience/Masters/RobotGym/robomimic/llminterface/llm_utils.py", line 95, in lm
    time.sleep(sleep_time)
KeyboardInterrupt
